# Making Machine Learning Models Interpretable

Notebook and libraries collection on how to make all (most) of ML models interpretable. Most of the models and coding here were taken from **Interpretable Machine Learning with Python** book written by Serg Masis (2022) and **Interpretable Machine Learning** book by Christoph Molnar (2021).

## Purpose

The purpose I made this repository is to learn and help people especially in the business field to be able to leverage Machine Learning models and make it accessible for the team who are not familiar into this Machine Learning models. By this, we can:

- Make an accurate prediction based on black box models
- Interpret all of these black box models
- Understand correlation and causation from Data Science approach instead of traditional causality diagram

## Models

Interpretable models which are being discussed here are:

- Act 1:
  - Traditional Models like Regression, Decision Tree, etc.
  - Explainable Boosting Model (EBM) and SkopeRules
    
- Act 2:
  - Permutation Feature Importance (PFI)
  - Partial Dependence Plots (PDPs)
  - Individual Conditional Expectation (ICE)
  - Centered ICE (cICE)
    
- Act 3:
  - SHapley Additive exPlanations (SHAP)
  - Accumulated Local Effects (ALE)

## About Dataset
 
Most of the dataset here were taken from Kaggle public dataset. The respective dataset will be written on the notebook itself.
